{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca130dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autotsc import utils\n",
    "import os\n",
    "from aeon.datasets.tsc_datasets import univariate\n",
    "import random\n",
    "from itertools import product\n",
    "from tqdm import tqdm\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "from time import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from aeon.classification.convolution_based import RocketClassifier, MiniRocketClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from aeon.transformations.collection import Normalizer\n",
    "from aeon.classification.sklearn import SklearnClassifierWrapper\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from time import perf_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0565c2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dir = \"experiments/automl_ca_vs_time_correlation\"\n",
    "os.makedirs(write_dir, exist_ok=True)\n",
    "\n",
    "datasets = list(univariate)\n",
    "random.shuffle(datasets)\n",
    "model_types = ['raw-scale-ridge', 'quant', 'minirocket', 'catch22', 'hydra', 'tabpfn', 'shapelet']\n",
    "\n",
    "n_jobs = 4\n",
    "n_runs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60f309c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_name):\n",
    "    from sklearn.linear_model import RidgeClassifier\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "    from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "    from aeon.classification.interval_based import QUANTClassifier\n",
    "    from aeon.classification.feature_based import Catch22Classifier\n",
    "    from aeon.classification.convolution_based import HydraClassifier\n",
    "    from aeon.classification.shapelet_based import ShapeletTransformClassifier\n",
    "    from tabpfn import TabPFNClassifier\n",
    "\n",
    "    if model_name == 'raw-scale-ridge':\n",
    "        return SklearnClassifierWrapper(\n",
    "            make_pipeline(\n",
    "                StandardScaler(),\n",
    "                RidgeClassifierCV(alphas=np.logspace(-3, 3, 10))\n",
    "            )\n",
    "        )\n",
    "    elif model_name == 'tabpfn':\n",
    "        return SklearnClassifierWrapper(\n",
    "            TabPFNClassifier(n_preprocessing_jobs=n_jobs)\n",
    "        )\n",
    "    elif model_name == 'quant':\n",
    "        return QUANTClassifier()\n",
    "    elif model_name == 'minirocket':\n",
    "        return MiniRocketClassifier(n_jobs=n_jobs)\n",
    "    elif model_name == 'catch22':\n",
    "        return Catch22Classifier(n_jobs=n_jobs)\n",
    "    elif model_name == 'hydra':\n",
    "        return HydraClassifier(n_jobs=n_jobs)\n",
    "    elif model_name == 'shapelet':\n",
    "        return ShapeletTransformClassifier(n_jobs=n_jobs)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model: {model_name}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7167188",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 1/4480 [00:00<27:27,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'Chinatown', 'run': 0, 'model': 'shapelet'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 7/4480 [00:13<2:32:15,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'Chinatown', 'run': 1, 'model': 'shapelet'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 14/4480 [00:21<1:50:04,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'Chinatown', 'run': 2, 'model': 'shapelet'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 21/4480 [00:29<1:36:43,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'Chinatown', 'run': 3, 'model': 'shapelet'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   1%|          | 28/4480 [00:36<1:30:41,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'Chinatown', 'run': 4, 'model': 'shapelet'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   1%|          | 41/4480 [00:44<1:01:23,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'GestureMidAirD2', 'run': 0, 'model': 'tabpfn'}\n",
      "Error processing GestureMidAirD2, run 0, model tabpfn: Number of classes 26 exceeds the maximal number of classes supported by TabPFN. Consider using a strategy to reduce the number of classes. For code see https://github.com/PriorLabs/tabpfn-extensions/blob/main/src/tabpfn_extensions/many_class/many_class_classifier.py\n",
      "Processing {'dataset': 'GestureMidAirD2', 'run': 0, 'model': 'shapelet'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   1%|          | 42/4480 [01:34<5:08:27,  4.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'GestureMidAirD2', 'run': 1, 'model': 'tabpfn'}\n",
      "Error processing GestureMidAirD2, run 1, model tabpfn: Number of classes 26 exceeds the maximal number of classes supported by TabPFN. Consider using a strategy to reduce the number of classes. For code see https://github.com/PriorLabs/tabpfn-extensions/blob/main/src/tabpfn_extensions/many_class/many_class_classifier.py\n",
      "Processing {'dataset': 'GestureMidAirD2', 'run': 1, 'model': 'shapelet'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   1%|          | 49/4480 [02:24<6:36:31,  5.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'GestureMidAirD2', 'run': 2, 'model': 'tabpfn'}\n",
      "Error processing GestureMidAirD2, run 2, model tabpfn: Number of classes 26 exceeds the maximal number of classes supported by TabPFN. Consider using a strategy to reduce the number of classes. For code see https://github.com/PriorLabs/tabpfn-extensions/blob/main/src/tabpfn_extensions/many_class/many_class_classifier.py\n",
      "Processing {'dataset': 'GestureMidAirD2', 'run': 2, 'model': 'shapelet'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   1%|▏         | 56/4480 [03:14<7:21:28,  5.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'GestureMidAirD2', 'run': 3, 'model': 'tabpfn'}\n",
      "Error processing GestureMidAirD2, run 3, model tabpfn: Number of classes 26 exceeds the maximal number of classes supported by TabPFN. Consider using a strategy to reduce the number of classes. For code see https://github.com/PriorLabs/tabpfn-extensions/blob/main/src/tabpfn_extensions/many_class/many_class_classifier.py\n",
      "Processing {'dataset': 'GestureMidAirD2', 'run': 3, 'model': 'shapelet'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   1%|▏         | 63/4480 [04:03<7:47:54,  6.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'GestureMidAirD2', 'run': 4, 'model': 'tabpfn'}\n",
      "Error processing GestureMidAirD2, run 4, model tabpfn: Number of classes 26 exceeds the maximal number of classes supported by TabPFN. Consider using a strategy to reduce the number of classes. For code see https://github.com/PriorLabs/tabpfn-extensions/blob/main/src/tabpfn_extensions/many_class/many_class_classifier.py\n",
      "Processing {'dataset': 'GestureMidAirD2', 'run': 4, 'model': 'shapelet'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   2%|▏         | 76/4480 [04:53<5:45:29,  4.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'GestureMidAirD1', 'run': 0, 'model': 'tabpfn'}\n",
      "Error processing GestureMidAirD1, run 0, model tabpfn: Number of classes 26 exceeds the maximal number of classes supported by TabPFN. Consider using a strategy to reduce the number of classes. For code see https://github.com/PriorLabs/tabpfn-extensions/blob/main/src/tabpfn_extensions/many_class/many_class_classifier.py\n",
      "Processing {'dataset': 'GestureMidAirD1', 'run': 0, 'model': 'shapelet'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   2%|▏         | 77/4480 [05:43<9:18:47,  7.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'GestureMidAirD1', 'run': 1, 'model': 'tabpfn'}\n",
      "Error processing GestureMidAirD1, run 1, model tabpfn: Number of classes 26 exceeds the maximal number of classes supported by TabPFN. Consider using a strategy to reduce the number of classes. For code see https://github.com/PriorLabs/tabpfn-extensions/blob/main/src/tabpfn_extensions/many_class/many_class_classifier.py\n",
      "Processing {'dataset': 'GestureMidAirD1', 'run': 1, 'model': 'shapelet'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   2%|▏         | 84/4480 [06:33<9:03:28,  7.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'GestureMidAirD1', 'run': 2, 'model': 'tabpfn'}\n",
      "Error processing GestureMidAirD1, run 2, model tabpfn: Number of classes 26 exceeds the maximal number of classes supported by TabPFN. Consider using a strategy to reduce the number of classes. For code see https://github.com/PriorLabs/tabpfn-extensions/blob/main/src/tabpfn_extensions/many_class/many_class_classifier.py\n",
      "Processing {'dataset': 'GestureMidAirD1', 'run': 2, 'model': 'shapelet'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   2%|▏         | 91/4480 [07:22<8:52:54,  7.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'GestureMidAirD1', 'run': 3, 'model': 'tabpfn'}\n",
      "Error processing GestureMidAirD1, run 3, model tabpfn: Number of classes 26 exceeds the maximal number of classes supported by TabPFN. Consider using a strategy to reduce the number of classes. For code see https://github.com/PriorLabs/tabpfn-extensions/blob/main/src/tabpfn_extensions/many_class/many_class_classifier.py\n",
      "Processing {'dataset': 'GestureMidAirD1', 'run': 3, 'model': 'shapelet'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   2%|▏         | 98/4480 [08:12<8:49:50,  7.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'GestureMidAirD1', 'run': 4, 'model': 'tabpfn'}\n",
      "Error processing GestureMidAirD1, run 4, model tabpfn: Number of classes 26 exceeds the maximal number of classes supported by TabPFN. Consider using a strategy to reduce the number of classes. For code see https://github.com/PriorLabs/tabpfn-extensions/blob/main/src/tabpfn_extensions/many_class/many_class_classifier.py\n",
      "Processing {'dataset': 'GestureMidAirD1', 'run': 4, 'model': 'shapelet'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   2%|▏         | 105/4480 [09:03<8:47:31,  7.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'NonInvasiveFetalECGThorax1', 'run': 0, 'model': 'tabpfn'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   2%|▏         | 111/4480 [09:03<6:18:13,  5.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing NonInvasiveFetalECGThorax1, run 0, model tabpfn: Number of classes 42 exceeds the maximal number of classes supported by TabPFN. Consider using a strategy to reduce the number of classes. For code see https://github.com/PriorLabs/tabpfn-extensions/blob/main/src/tabpfn_extensions/many_class/many_class_classifier.py\n",
      "Processing {'dataset': 'NonInvasiveFetalECGThorax1', 'run': 0, 'model': 'shapelet'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   3%|▎         | 118/4480 [18:34<32:16:49, 26.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'NonInvasiveFetalECGThorax1', 'run': 1, 'model': 'tabpfn'}\n",
      "Error processing NonInvasiveFetalECGThorax1, run 1, model tabpfn: Number of classes 42 exceeds the maximal number of classes supported by TabPFN. Consider using a strategy to reduce the number of classes. For code see https://github.com/PriorLabs/tabpfn-extensions/blob/main/src/tabpfn_extensions/many_class/many_class_classifier.py\n",
      "Processing {'dataset': 'NonInvasiveFetalECGThorax1', 'run': 1, 'model': 'shapelet'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   3%|▎         | 125/4480 [28:02<49:52:56, 41.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'NonInvasiveFetalECGThorax1', 'run': 2, 'model': 'tabpfn'}\n",
      "Error processing NonInvasiveFetalECGThorax1, run 2, model tabpfn: Number of classes 42 exceeds the maximal number of classes supported by TabPFN. Consider using a strategy to reduce the number of classes. For code see https://github.com/PriorLabs/tabpfn-extensions/blob/main/src/tabpfn_extensions/many_class/many_class_classifier.py\n",
      "Processing {'dataset': 'NonInvasiveFetalECGThorax1', 'run': 2, 'model': 'shapelet'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   3%|▎         | 132/4480 [37:30<60:11:03, 49.83s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'NonInvasiveFetalECGThorax1', 'run': 3, 'model': 'tabpfn'}\n",
      "Error processing NonInvasiveFetalECGThorax1, run 3, model tabpfn: Number of classes 42 exceeds the maximal number of classes supported by TabPFN. Consider using a strategy to reduce the number of classes. For code see https://github.com/PriorLabs/tabpfn-extensions/blob/main/src/tabpfn_extensions/many_class/many_class_classifier.py\n",
      "Processing {'dataset': 'NonInvasiveFetalECGThorax1', 'run': 3, 'model': 'shapelet'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   3%|▎         | 139/4480 [46:58<65:45:03, 54.53s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'NonInvasiveFetalECGThorax1', 'run': 4, 'model': 'tabpfn'}\n",
      "Error processing NonInvasiveFetalECGThorax1, run 4, model tabpfn: Number of classes 42 exceeds the maximal number of classes supported by TabPFN. Consider using a strategy to reduce the number of classes. For code see https://github.com/PriorLabs/tabpfn-extensions/blob/main/src/tabpfn_extensions/many_class/many_class_classifier.py\n",
      "Processing {'dataset': 'NonInvasiveFetalECGThorax1', 'run': 4, 'model': 'shapelet'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   3%|▎         | 140/4480 [56:31<125:14:24, 103.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'UWaveGestureLibraryAll', 'run': 0, 'model': 'shapelet'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   3%|▎         | 147/4480 [1:15:35<159:56:11, 132.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'UWaveGestureLibraryAll', 'run': 1, 'model': 'shapelet'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   3%|▎         | 154/4480 [1:34:32<174:16:56, 145.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'UWaveGestureLibraryAll', 'run': 2, 'model': 'shapelet'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   4%|▎         | 161/4480 [1:53:37<182:13:28, 151.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'UWaveGestureLibraryAll', 'run': 3, 'model': 'shapelet'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   4%|▍         | 168/4480 [2:12:34<186:17:16, 155.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'UWaveGestureLibraryAll', 'run': 4, 'model': 'shapelet'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   4%|▍         | 181/4480 [2:31:38<134:25:09, 112.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'FacesUCR', 'run': 0, 'model': 'tabpfn'}\n",
      "Error processing FacesUCR, run 0, model tabpfn: Number of classes 14 exceeds the maximal number of classes supported by TabPFN. Consider using a strategy to reduce the number of classes. For code see https://github.com/PriorLabs/tabpfn-extensions/blob/main/src/tabpfn_extensions/many_class/many_class_classifier.py\n",
      "Processing {'dataset': 'FacesUCR', 'run': 0, 'model': 'shapelet'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   4%|▍         | 182/4480 [2:32:22<129:07:29, 108.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'FacesUCR', 'run': 1, 'model': 'tabpfn'}\n",
      "Error processing FacesUCR, run 1, model tabpfn: Number of classes 14 exceeds the maximal number of classes supported by TabPFN. Consider using a strategy to reduce the number of classes. For code see https://github.com/PriorLabs/tabpfn-extensions/blob/main/src/tabpfn_extensions/many_class/many_class_classifier.py\n",
      "Processing {'dataset': 'FacesUCR', 'run': 1, 'model': 'shapelet'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   4%|▍         | 189/4480 [2:33:05<81:24:13, 68.30s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'FacesUCR', 'run': 2, 'model': 'tabpfn'}\n",
      "Error processing FacesUCR, run 2, model tabpfn: Number of classes 14 exceeds the maximal number of classes supported by TabPFN. Consider using a strategy to reduce the number of classes. For code see https://github.com/PriorLabs/tabpfn-extensions/blob/main/src/tabpfn_extensions/many_class/many_class_classifier.py\n",
      "Processing {'dataset': 'FacesUCR', 'run': 2, 'model': 'shapelet'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   4%|▍         | 196/4480 [2:33:49<54:49:21, 46.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'FacesUCR', 'run': 3, 'model': 'tabpfn'}\n",
      "Error processing FacesUCR, run 3, model tabpfn: Number of classes 14 exceeds the maximal number of classes supported by TabPFN. Consider using a strategy to reduce the number of classes. For code see https://github.com/PriorLabs/tabpfn-extensions/blob/main/src/tabpfn_extensions/many_class/many_class_classifier.py\n",
      "Processing {'dataset': 'FacesUCR', 'run': 3, 'model': 'shapelet'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   5%|▍         | 203/4480 [2:34:33<38:43:15, 32.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'FacesUCR', 'run': 4, 'model': 'tabpfn'}\n",
      "Error processing FacesUCR, run 4, model tabpfn: Number of classes 14 exceeds the maximal number of classes supported by TabPFN. Consider using a strategy to reduce the number of classes. For code see https://github.com/PriorLabs/tabpfn-extensions/blob/main/src/tabpfn_extensions/many_class/many_class_classifier.py\n",
      "Processing {'dataset': 'FacesUCR', 'run': 4, 'model': 'shapelet'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   5%|▍         | 216/4480 [2:35:17<20:19:30, 17.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'CricketY', 'run': 0, 'model': 'tabpfn'}\n",
      "Error processing CricketY, run 0, model tabpfn: Number of classes 12 exceeds the maximal number of classes supported by TabPFN. Consider using a strategy to reduce the number of classes. For code see https://github.com/PriorLabs/tabpfn-extensions/blob/main/src/tabpfn_extensions/many_class/many_class_classifier.py\n",
      "Processing {'dataset': 'CricketY', 'run': 0, 'model': 'shapelet'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   5%|▍         | 223/4480 [2:36:43<16:31:16, 13.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'CricketY', 'run': 1, 'model': 'tabpfn'}\n",
      "Error processing CricketY, run 1, model tabpfn: Number of classes 12 exceeds the maximal number of classes supported by TabPFN. Consider using a strategy to reduce the number of classes. For code see https://github.com/PriorLabs/tabpfn-extensions/blob/main/src/tabpfn_extensions/many_class/many_class_classifier.py\n",
      "Processing {'dataset': 'CricketY', 'run': 1, 'model': 'shapelet'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   5%|▌         | 230/4480 [2:38:10<13:55:36, 11.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'CricketY', 'run': 2, 'model': 'tabpfn'}\n",
      "Error processing CricketY, run 2, model tabpfn: Number of classes 12 exceeds the maximal number of classes supported by TabPFN. Consider using a strategy to reduce the number of classes. For code see https://github.com/PriorLabs/tabpfn-extensions/blob/main/src/tabpfn_extensions/many_class/many_class_classifier.py\n",
      "Processing {'dataset': 'CricketY', 'run': 2, 'model': 'shapelet'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   5%|▌         | 237/4480 [2:39:37<12:23:25, 10.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'CricketY', 'run': 3, 'model': 'tabpfn'}\n",
      "Error processing CricketY, run 3, model tabpfn: Number of classes 12 exceeds the maximal number of classes supported by TabPFN. Consider using a strategy to reduce the number of classes. For code see https://github.com/PriorLabs/tabpfn-extensions/blob/main/src/tabpfn_extensions/many_class/many_class_classifier.py\n",
      "Processing {'dataset': 'CricketY', 'run': 3, 'model': 'shapelet'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   5%|▌         | 244/4480 [2:41:04<11:32:00,  9.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'CricketY', 'run': 4, 'model': 'tabpfn'}\n",
      "Error processing CricketY, run 4, model tabpfn: Number of classes 12 exceeds the maximal number of classes supported by TabPFN. Consider using a strategy to reduce the number of classes. For code see https://github.com/PriorLabs/tabpfn-extensions/blob/main/src/tabpfn_extensions/many_class/many_class_classifier.py\n",
      "Processing {'dataset': 'CricketY', 'run': 4, 'model': 'shapelet'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   5%|▌         | 245/4480 [2:42:31<20:09:20, 17.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'BirdChicken', 'run': 0, 'model': 'shapelet'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   6%|▌         | 252/4480 [2:42:42<11:12:47,  9.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'BirdChicken', 'run': 1, 'model': 'shapelet'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   6%|▌         | 259/4480 [2:42:53<7:20:08,  6.26s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'BirdChicken', 'run': 2, 'model': 'shapelet'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   6%|▌         | 266/4480 [2:43:03<5:16:44,  4.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'BirdChicken', 'run': 3, 'model': 'shapelet'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   6%|▌         | 273/4480 [2:43:14<4:04:03,  3.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'BirdChicken', 'run': 4, 'model': 'shapelet'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   6%|▋         | 280/4480 [2:43:25<3:18:19,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'SmallKitchenAppliances', 'run': 0, 'model': 'shapelet'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   6%|▋         | 287/4480 [2:47:30<15:18:18, 13.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'SmallKitchenAppliances', 'run': 1, 'model': 'shapelet'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   7%|▋         | 294/4480 [2:51:34<23:13:29, 19.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'SmallKitchenAppliances', 'run': 2, 'model': 'shapelet'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   7%|▋         | 301/4480 [2:55:37<28:28:38, 24.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'SmallKitchenAppliances', 'run': 3, 'model': 'shapelet'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   7%|▋         | 308/4480 [2:59:38<31:58:42, 27.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'SmallKitchenAppliances', 'run': 4, 'model': 'shapelet'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   7%|▋         | 315/4480 [3:03:44<34:33:01, 29.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'HouseTwenty', 'run': 0, 'model': 'shapelet'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   7%|▋         | 322/4480 [3:06:49<33:18:44, 28.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'HouseTwenty', 'run': 1, 'model': 'shapelet'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   7%|▋         | 329/4480 [3:09:52<32:19:45, 28.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'HouseTwenty', 'run': 2, 'model': 'shapelet'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   8%|▊         | 336/4480 [3:12:54<31:33:49, 27.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'HouseTwenty', 'run': 3, 'model': 'shapelet'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   8%|▊         | 343/4480 [3:15:58<31:06:15, 27.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'HouseTwenty', 'run': 4, 'model': 'shapelet'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   8%|▊         | 349/4480 [3:18:11<39:05:54, 34.07s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     28\u001b[39m     last_dataset = ds\n\u001b[32m     30\u001b[39m start_time = perf_counter()\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m training_time = perf_counter() - start_time\n\u001b[32m     33\u001b[39m y_pred = model.predict(X_test)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/repos/AutoTSC/.venv/lib/python3.12/site-packages/aeon/classification/base.py:112\u001b[39m, in \u001b[36mBaseClassifier.fit\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    109\u001b[39m X, y, single_class = \u001b[38;5;28mself\u001b[39m._fit_setup(X, y)\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m single_class:\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    114\u001b[39m \u001b[38;5;66;03m# this should happen last\u001b[39;00m\n\u001b[32m    115\u001b[39m \u001b[38;5;28mself\u001b[39m.is_fitted = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/repos/AutoTSC/.venv/lib/python3.12/site-packages/aeon/classification/shapelet_based/_stc.py:182\u001b[39m, in \u001b[36mShapeletTransformClassifier._fit\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_fit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[32m    163\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Fit ShapeletTransformClassifier to training data.\u001b[39;00m\n\u001b[32m    164\u001b[39m \n\u001b[32m    165\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    180\u001b[39m \u001b[33;03m    ending in \"_\".\u001b[39;00m\n\u001b[32m    181\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m182\u001b[39m     X_t = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_stc_shared\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose:\n\u001b[32m    185\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mFitting estimator...\u001b[39m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# noqa: T201\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/repos/AutoTSC/.venv/lib/python3.12/site-packages/aeon/classification/shapelet_based/_stc.py:367\u001b[39m, in \u001b[36mShapeletTransformClassifier._fit_stc_shared\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    364\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose:\n\u001b[32m    365\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mFitting and transforming shapelets...\u001b[39m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# noqa: T201\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m367\u001b[39m X_t = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_transformer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    368\u001b[39m X_t = np.nan_to_num(X_t, \u001b[38;5;28;01mFalse\u001b[39;00m, -\u001b[32m1\u001b[39m, -\u001b[32m1\u001b[39m, -\u001b[32m1\u001b[39m)\n\u001b[32m    370\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/repos/AutoTSC/.venv/lib/python3.12/site-packages/aeon/transformations/collection/base.py:206\u001b[39m, in \u001b[36mBaseCollectionTransformer.fit_transform\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    204\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_y(y, n_cases=\u001b[38;5;28mself\u001b[39m.metadata_[\u001b[33m\"\u001b[39m\u001b[33mn_cases\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m Xt = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[38;5;28mself\u001b[39m.is_fitted = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    209\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Xt\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/repos/AutoTSC/.venv/lib/python3.12/site-packages/aeon/transformations/collection/shapelet_based/_shapelet_transform.py:206\u001b[39m, in \u001b[36mRandomShapeletTransform._fit_transform\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_fit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_shapelets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_distances\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/repos/AutoTSC/.venv/lib/python3.12/site-packages/aeon/transformations/collection/shapelet_based/_shapelet_transform.py:322\u001b[39m, in \u001b[36mRandomShapeletTransform._fit_shapelets\u001b[39m\u001b[34m(self, X, y, save_distances)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m n_shapelets_extracted < \u001b[38;5;28mself\u001b[39m.n_shapelet_samples:\n\u001b[32m    315\u001b[39m     n_shapelets_to_extract = (\n\u001b[32m    316\u001b[39m         \u001b[38;5;28mself\u001b[39m._batch_size\n\u001b[32m    317\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_shapelets_extracted + \u001b[38;5;28mself\u001b[39m._batch_size\n\u001b[32m    318\u001b[39m         <= \u001b[38;5;28mself\u001b[39m.n_shapelet_samples\n\u001b[32m    319\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.n_shapelet_samples - n_shapelets_extracted\n\u001b[32m    320\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m     p = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    323\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_n_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparallel_backend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefer\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mthreads\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m    324\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    325\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_extract_random_shapelet\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    326\u001b[39m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    327\u001b[39m \u001b[43m            \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    328\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_shapelets_extracted\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcheck_random_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrng\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrandint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43miinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mint32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmax\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    331\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_shapelets_to_extract\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    333\u001b[39m     candidate_shapelets, candidate_distances = \u001b[38;5;28mzip\u001b[39m(*p)\n\u001b[32m    335\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m save_distances:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/repos/AutoTSC/.venv/lib/python3.12/site-packages/joblib/parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/repos/AutoTSC/.venv/lib/python3.12/site-packages/joblib/parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/repos/AutoTSC/.venv/lib/python3.12/site-packages/joblib/parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "all_combinations = list(product(datasets, range(n_runs), model_types))\n",
    "\n",
    "last_dataset = None\n",
    "X_train, y_train, X_test, y_test = None, None, None, None\n",
    "\n",
    "for ds, run, model_name in tqdm(all_combinations, desc=\"Processing\"):\n",
    "    try: \n",
    "        model = get_model(model_name)\n",
    "        stats = {\n",
    "            \"dataset\": ds,\n",
    "            \"run\": run,\n",
    "            \"model\": model_name,\n",
    "        }\n",
    "\n",
    "        hash_val = pl.DataFrame([stats]).hash_rows(\n",
    "            seed=42, seed_1=1, seed_2=2, seed_3=3\n",
    "        ).item()\n",
    "        file = f\"{write_dir}/{hash_val}.parquet\"\n",
    "\n",
    "        if os.path.exists(file):\n",
    "            #print(f'Skipping {stats}')\n",
    "            continue\n",
    "        else:\n",
    "            print(f'Processing {stats}')\n",
    "\n",
    "        if ds != last_dataset:\n",
    "            X_train, y_train, X_test, y_test = utils.load_dataset(ds)\n",
    "            last_dataset = ds\n",
    "\n",
    "        start_time = perf_counter()\n",
    "        model.fit(X_train, y_train)\n",
    "        training_time = perf_counter() - start_time\n",
    "        y_pred = model.predict(X_test)\n",
    "        test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        stats[\"test_accuracy\"] = test_accuracy\n",
    "        stats[\"training_time\"] = training_time\n",
    "\n",
    "        df_stat = pl.DataFrame([stats])\n",
    "        df_stat.write_parquet(file)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {ds}, run {run}, model {model_name}: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4a24ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_parquet(f'{write_dir}/*.parquet').filter(pl.col(\"dataset\").is_in(datasets))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f286f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74f14a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = df.group_by('dataset', 'model').agg([\n",
    "    pl.col('test_accuracy').mean()\n",
    "]).sort('test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4c4df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "together_dataset = set(\n",
    "    gdf.filter(pl.col('model') == 'tabpfn')['dataset']\n",
    ").intersection(\n",
    "    set(gdf.filter(pl.col('model') == 'quant')['dataset'])\n",
    ")\n",
    "v1 = gdf.filter(pl.col('model') == 'tabpfn').filter(pl.col('dataset').is_in(together_dataset)).sort('dataset')['test_accuracy']\n",
    "v2 = gdf.filter(pl.col('model') == 'quant').filter(pl.col('dataset').is_in(together_dataset)).sort('dataset')['test_accuracy']\n",
    "plt.scatter(v1, v2)\n",
    "# plot read line y=x\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--')\n",
    "plt.xlabel('TabPFN Test Accuracy')\n",
    "plt.ylabel('QUANT Test Accuracy')\n",
    "plt.title('Model Performance Comparison: TabPFN vs QUANT')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8816476",
   "metadata": {},
   "outputs": [],
   "source": [
    "together_dataset = set(\n",
    "    gdf.filter(pl.col('model') == 'tabpfn')['dataset']\n",
    ").intersection(\n",
    "    set(gdf.filter(pl.col('model') == 'raw-scale-ridge')['dataset'])\n",
    ")\n",
    "v1 = gdf.filter(pl.col('model') == 'tabpfn').filter(pl.col('dataset').is_in(together_dataset)).sort('dataset')['test_accuracy']\n",
    "v2 = gdf.filter(pl.col('model') == 'raw-scale-ridge').filter(pl.col('dataset').is_in(together_dataset)).sort('dataset')['test_accuracy']\n",
    "plt.scatter(v1, v2)\n",
    "# plot read line y=x\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--')\n",
    "plt.xlabel('TabPFN Test Accuracy')\n",
    "plt.ylabel('Raw-scale Ridge Classifier Accuracy')\n",
    "plt.title('Model Performance Comparison: TabPFN vs Raw-scale Ridge Classifier')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a901b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = gdf.filter(pl.col('model') == 'raw-scale-ridge').sort('dataset')['test_accuracy']\n",
    "v2 = gdf.filter(pl.col('model') == 'quant').sort('dataset')['test_accuracy']\n",
    "plt.scatter(v1, v2)\n",
    "# plot read line y=x\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--')\n",
    "plt.xlabel('Raw-scale Ridge Classifier Accuracy')\n",
    "plt.ylabel('QUANT Classifier Accuracy')\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f400d556",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = gdf.filter(pl.col('model') == 'quant').sort('dataset')['test_accuracy']\n",
    "v2 = gdf.filter(pl.col('model') == 'minirocket').sort('dataset')['test_accuracy']\n",
    "plt.scatter(v1, v2)\n",
    "# plot read line y=x\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--')\n",
    "plt.xlabel('QUANT Classifier Accuracy')\n",
    "plt.ylabel('MiniRocket Classifier Accuracy')\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912d36fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = gdf.filter(pl.col('model') == 'catch22').sort('dataset')['test_accuracy']\n",
    "v2 = gdf.filter(pl.col('model') == 'minirocket').sort('dataset')['test_accuracy']\n",
    "plt.scatter(v1, v2)\n",
    "# plot read line y=x\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--')\n",
    "plt.xlabel('Catch22 Classifier Accuracy')\n",
    "plt.ylabel('MiniRocket Classifier Accuracy')\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22586e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = gdf.filter(pl.col('model') == 'catch22').sort('dataset')['test_accuracy']\n",
    "v2 = gdf.filter(pl.col('model') == 'raw-scale-ridge').sort('dataset')['test_accuracy']\n",
    "plt.scatter(v1, v2)\n",
    "# plot read line y=x\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--')\n",
    "plt.xlabel('Catch22 Classifier Accuracy')\n",
    "plt.ylabel('Raw-scale Ridge Classifier Accuracy')\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3ba214",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = df.group_by('dataset', 'model').agg([\n",
    "    pl.col('training_time').mean()\n",
    "]).sort('dataset', 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e4ddbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 20))\n",
    "sns.stripplot(data=gdf, y=\"dataset\", x=\"training_time\", hue=\"model\", dodge=False)\n",
    "plt.grid(True)\n",
    "plt.xscale('log')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e873dfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = df.group_by('dataset', 'model').agg([\n",
    "    pl.col('test_accuracy').mean()\n",
    "]).sort('dataset', 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41ce67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dataset'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2543e135",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 20))\n",
    "sns.stripplot(data=gdf, y=\"dataset\", x=\"test_accuracy\", hue=\"model\", dodge=False)\n",
    "plt.grid(True)\n",
    "plt.xscale('log')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d244e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = df.group_by('dataset', 'model').agg([\n",
    "    pl.col('test_accuracy').mean(),\n",
    "    pl.col('training_time').mean()\n",
    "]).sort('dataset', 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9a0bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=gdf, x='training_time', y='test_accuracy', hue='model')\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08d6386",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AutoTSC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
