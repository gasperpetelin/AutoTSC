{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca130dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autotsc import utils\n",
    "import os\n",
    "from aeon.datasets.tsc_datasets import univariate\n",
    "import random\n",
    "from itertools import product\n",
    "from tqdm import tqdm\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "from time import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from aeon.classification.convolution_based import RocketClassifier, MiniRocketClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from aeon.transformations.collection import Normalizer\n",
    "from aeon.classification.sklearn import SklearnClassifierWrapper\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from time import perf_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0565c2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dir = \"experiments/automl_ca_vs_time_correlation\"\n",
    "os.makedirs(write_dir, exist_ok=True)\n",
    "\n",
    "datasets = list(univariate)\n",
    "random.shuffle(datasets)\n",
    "model_types = ['raw-scale-ridge', 'quant', 'minirocket', 'catch22', 'hydra', 'tabpfn']#, 'shapelet']\n",
    "\n",
    "n_jobs = 4\n",
    "n_runs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60f309c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_name):\n",
    "    from sklearn.linear_model import RidgeClassifier\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "    from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "    from aeon.classification.interval_based import QUANTClassifier\n",
    "    from aeon.classification.feature_based import Catch22Classifier\n",
    "    from aeon.classification.convolution_based import HydraClassifier\n",
    "    from aeon.classification.shapelet_based import ShapeletTransformClassifier\n",
    "    from tabpfn import TabPFNClassifier\n",
    "\n",
    "    if model_name == 'raw-scale-ridge':\n",
    "        return SklearnClassifierWrapper(\n",
    "            make_pipeline(\n",
    "                StandardScaler(),\n",
    "                RidgeClassifierCV(alphas=np.logspace(-3, 3, 10))\n",
    "            )\n",
    "        )\n",
    "    elif model_name == 'tabpfn':\n",
    "        return SklearnClassifierWrapper(\n",
    "            TabPFNClassifier(n_preprocessing_jobs=n_jobs)\n",
    "        )\n",
    "    elif model_name == 'quant':\n",
    "        return QUANTClassifier()\n",
    "    elif model_name == 'minirocket':\n",
    "        return MiniRocketClassifier(n_jobs=n_jobs)\n",
    "    elif model_name == 'catch22':\n",
    "        return Catch22Classifier(n_jobs=n_jobs)\n",
    "    elif model_name == 'hydra':\n",
    "        return HydraClassifier(n_jobs=n_jobs)\n",
    "    elif model_name == 'shapelet':\n",
    "        return ShapeletTransformClassifier(n_jobs=n_jobs)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model: {model_name}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7167188",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 1/3840 [00:00<22:57,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'Crop', 'run': 0, 'model': 'tabpfn'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 12/3840 [00:00<03:31, 18.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Crop, run 0, model tabpfn: Number of classes 24 exceeds the maximal number of classes supported by TabPFN. Consider using a strategy to reduce the number of classes. For code see https://github.com/PriorLabs/tabpfn-extensions/blob/main/src/tabpfn_extensions/many_class/many_class_classifier.py\n",
      "Processing {'dataset': 'Crop', 'run': 1, 'model': 'tabpfn'}\n",
      "Error processing Crop, run 1, model tabpfn: Number of classes 24 exceeds the maximal number of classes supported by TabPFN. Consider using a strategy to reduce the number of classes. For code see https://github.com/PriorLabs/tabpfn-extensions/blob/main/src/tabpfn_extensions/many_class/many_class_classifier.py\n",
      "Processing {'dataset': 'Crop', 'run': 2, 'model': 'tabpfn'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   1%|          | 24/3840 [00:00<01:46, 35.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Crop, run 2, model tabpfn: Number of classes 24 exceeds the maximal number of classes supported by TabPFN. Consider using a strategy to reduce the number of classes. For code see https://github.com/PriorLabs/tabpfn-extensions/blob/main/src/tabpfn_extensions/many_class/many_class_classifier.py\n",
      "Processing {'dataset': 'Crop', 'run': 3, 'model': 'tabpfn'}\n",
      "Error processing Crop, run 3, model tabpfn: Number of classes 24 exceeds the maximal number of classes supported by TabPFN. Consider using a strategy to reduce the number of classes. For code see https://github.com/PriorLabs/tabpfn-extensions/blob/main/src/tabpfn_extensions/many_class/many_class_classifier.py\n",
      "Processing {'dataset': 'Crop', 'run': 4, 'model': 'tabpfn'}\n",
      "Error processing Crop, run 4, model tabpfn: Number of classes 24 exceeds the maximal number of classes supported by TabPFN. Consider using a strategy to reduce the number of classes. For code see https://github.com/PriorLabs/tabpfn-extensions/blob/main/src/tabpfn_extensions/many_class/many_class_classifier.py\n",
      "Processing {'dataset': 'FacesUCR', 'run': 0, 'model': 'tabpfn'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   1%|▏         | 48/3840 [00:01<01:09, 54.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing FacesUCR, run 0, model tabpfn: Number of classes 14 exceeds the maximal number of classes supported by TabPFN. Consider using a strategy to reduce the number of classes. For code see https://github.com/PriorLabs/tabpfn-extensions/blob/main/src/tabpfn_extensions/many_class/many_class_classifier.py\n",
      "Processing {'dataset': 'FacesUCR', 'run': 1, 'model': 'tabpfn'}\n",
      "Error processing FacesUCR, run 1, model tabpfn: Number of classes 14 exceeds the maximal number of classes supported by TabPFN. Consider using a strategy to reduce the number of classes. For code see https://github.com/PriorLabs/tabpfn-extensions/blob/main/src/tabpfn_extensions/many_class/many_class_classifier.py\n",
      "Processing {'dataset': 'FacesUCR', 'run': 2, 'model': 'tabpfn'}\n",
      "Error processing FacesUCR, run 2, model tabpfn: Number of classes 14 exceeds the maximal number of classes supported by TabPFN. Consider using a strategy to reduce the number of classes. For code see https://github.com/PriorLabs/tabpfn-extensions/blob/main/src/tabpfn_extensions/many_class/many_class_classifier.py\n",
      "Processing {'dataset': 'FacesUCR', 'run': 3, 'model': 'tabpfn'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   2%|▏         | 60/3840 [00:01<01:00, 62.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing FacesUCR, run 3, model tabpfn: Number of classes 14 exceeds the maximal number of classes supported by TabPFN. Consider using a strategy to reduce the number of classes. For code see https://github.com/PriorLabs/tabpfn-extensions/blob/main/src/tabpfn_extensions/many_class/many_class_classifier.py\n",
      "Processing {'dataset': 'FacesUCR', 'run': 4, 'model': 'tabpfn'}\n",
      "Error processing FacesUCR, run 4, model tabpfn: Number of classes 14 exceeds the maximal number of classes supported by TabPFN. Consider using a strategy to reduce the number of classes. For code see https://github.com/PriorLabs/tabpfn-extensions/blob/main/src/tabpfn_extensions/many_class/many_class_classifier.py\n",
      "Processing {'dataset': 'Lightning2', 'run': 0, 'model': 'raw-scale-ridge'}\n",
      "Processing {'dataset': 'Lightning2', 'run': 0, 'model': 'quant'}\n",
      "Processing {'dataset': 'Lightning2', 'run': 0, 'model': 'minirocket'}\n",
      "Processing {'dataset': 'Lightning2', 'run': 0, 'model': 'catch22'}\n",
      "Processing {'dataset': 'Lightning2', 'run': 0, 'model': 'hydra'}\n",
      "Processing {'dataset': 'Lightning2', 'run': 0, 'model': 'tabpfn'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   2%|▏         | 67/3840 [00:08<15:11,  4.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'Lightning2', 'run': 1, 'model': 'raw-scale-ridge'}\n",
      "Processing {'dataset': 'Lightning2', 'run': 1, 'model': 'quant'}\n",
      "Processing {'dataset': 'Lightning2', 'run': 1, 'model': 'minirocket'}\n",
      "Processing {'dataset': 'Lightning2', 'run': 1, 'model': 'catch22'}\n",
      "Processing {'dataset': 'Lightning2', 'run': 1, 'model': 'hydra'}\n",
      "Processing {'dataset': 'Lightning2', 'run': 1, 'model': 'tabpfn'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   2%|▏         | 72/3840 [00:10<18:30,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'Lightning2', 'run': 2, 'model': 'raw-scale-ridge'}\n",
      "Processing {'dataset': 'Lightning2', 'run': 2, 'model': 'quant'}\n",
      "Processing {'dataset': 'Lightning2', 'run': 2, 'model': 'minirocket'}\n",
      "Processing {'dataset': 'Lightning2', 'run': 2, 'model': 'catch22'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   2%|▏         | 76/3840 [00:11<17:35,  3.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'Lightning2', 'run': 2, 'model': 'hydra'}\n",
      "Processing {'dataset': 'Lightning2', 'run': 2, 'model': 'tabpfn'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   2%|▏         | 79/3840 [00:13<20:11,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'Lightning2', 'run': 3, 'model': 'raw-scale-ridge'}\n",
      "Processing {'dataset': 'Lightning2', 'run': 3, 'model': 'quant'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   2%|▏         | 81/3840 [00:13<19:46,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'Lightning2', 'run': 3, 'model': 'minirocket'}\n",
      "Processing {'dataset': 'Lightning2', 'run': 3, 'model': 'catch22'}\n",
      "Processing {'dataset': 'Lightning2', 'run': 3, 'model': 'hydra'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   2%|▏         | 83/3840 [00:14<20:47,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'Lightning2', 'run': 3, 'model': 'tabpfn'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   2%|▏         | 84/3840 [00:15<25:33,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'Lightning2', 'run': 4, 'model': 'raw-scale-ridge'}\n",
      "Processing {'dataset': 'Lightning2', 'run': 4, 'model': 'quant'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   2%|▏         | 87/3840 [00:16<20:40,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'Lightning2', 'run': 4, 'model': 'minirocket'}\n",
      "Processing {'dataset': 'Lightning2', 'run': 4, 'model': 'catch22'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   2%|▏         | 88/3840 [00:16<20:21,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'Lightning2', 'run': 4, 'model': 'hydra'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   2%|▏         | 89/3840 [00:17<22:45,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'Lightning2', 'run': 4, 'model': 'tabpfn'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   2%|▏         | 90/3840 [00:18<34:19,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'ProximalPhalanxOutlineCorrect', 'run': 0, 'model': 'raw-scale-ridge'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   2%|▏         | 91/3840 [00:19<36:43,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'ProximalPhalanxOutlineCorrect', 'run': 0, 'model': 'quant'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   2%|▏         | 92/3840 [00:19<38:32,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'ProximalPhalanxOutlineCorrect', 'run': 0, 'model': 'minirocket'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   2%|▏         | 93/3840 [00:20<33:00,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'ProximalPhalanxOutlineCorrect', 'run': 0, 'model': 'catch22'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   2%|▏         | 94/3840 [00:20<32:01,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'ProximalPhalanxOutlineCorrect', 'run': 0, 'model': 'hydra'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   2%|▏         | 95/3840 [00:21<31:02,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'ProximalPhalanxOutlineCorrect', 'run': 0, 'model': 'tabpfn'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   2%|▎         | 96/3840 [00:22<42:43,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'ProximalPhalanxOutlineCorrect', 'run': 1, 'model': 'raw-scale-ridge'}\n",
      "Processing {'dataset': 'ProximalPhalanxOutlineCorrect', 'run': 1, 'model': 'quant'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   3%|▎         | 98/3840 [00:22<33:07,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'ProximalPhalanxOutlineCorrect', 'run': 1, 'model': 'minirocket'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   3%|▎         | 99/3840 [00:23<29:19,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'ProximalPhalanxOutlineCorrect', 'run': 1, 'model': 'catch22'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   3%|▎         | 100/3840 [00:23<29:14,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'ProximalPhalanxOutlineCorrect', 'run': 1, 'model': 'hydra'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   3%|▎         | 101/3840 [00:24<29:08,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'ProximalPhalanxOutlineCorrect', 'run': 1, 'model': 'tabpfn'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   3%|▎         | 102/3840 [00:25<41:13,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'ProximalPhalanxOutlineCorrect', 'run': 2, 'model': 'raw-scale-ridge'}\n",
      "Processing {'dataset': 'ProximalPhalanxOutlineCorrect', 'run': 2, 'model': 'quant'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   3%|▎         | 104/3840 [00:26<33:38,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'ProximalPhalanxOutlineCorrect', 'run': 2, 'model': 'minirocket'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   3%|▎         | 105/3840 [00:26<37:04,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'ProximalPhalanxOutlineCorrect', 'run': 2, 'model': 'catch22'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   3%|▎         | 106/3840 [00:27<35:08,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'ProximalPhalanxOutlineCorrect', 'run': 2, 'model': 'hydra'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   3%|▎         | 107/3840 [00:27<33:13,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'ProximalPhalanxOutlineCorrect', 'run': 2, 'model': 'tabpfn'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   3%|▎         | 108/3840 [00:28<43:45,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'ProximalPhalanxOutlineCorrect', 'run': 3, 'model': 'raw-scale-ridge'}\n",
      "Processing {'dataset': 'ProximalPhalanxOutlineCorrect', 'run': 3, 'model': 'quant'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   3%|▎         | 110/3840 [00:29<33:40,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'ProximalPhalanxOutlineCorrect', 'run': 3, 'model': 'minirocket'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   3%|▎         | 111/3840 [00:29<29:40,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'ProximalPhalanxOutlineCorrect', 'run': 3, 'model': 'catch22'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   3%|▎         | 112/3840 [00:30<29:19,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'ProximalPhalanxOutlineCorrect', 'run': 3, 'model': 'hydra'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   3%|▎         | 113/3840 [00:30<28:49,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'ProximalPhalanxOutlineCorrect', 'run': 3, 'model': 'tabpfn'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   3%|▎         | 114/3840 [00:31<40:09,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'ProximalPhalanxOutlineCorrect', 'run': 4, 'model': 'raw-scale-ridge'}\n",
      "Processing {'dataset': 'ProximalPhalanxOutlineCorrect', 'run': 4, 'model': 'quant'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   3%|▎         | 116/3840 [00:32<32:17,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'ProximalPhalanxOutlineCorrect', 'run': 4, 'model': 'minirocket'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   3%|▎         | 117/3840 [00:32<29:02,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'ProximalPhalanxOutlineCorrect', 'run': 4, 'model': 'catch22'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   3%|▎         | 118/3840 [00:33<29:07,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'ProximalPhalanxOutlineCorrect', 'run': 4, 'model': 'hydra'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   3%|▎         | 119/3840 [00:33<28:58,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'ProximalPhalanxOutlineCorrect', 'run': 4, 'model': 'tabpfn'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   3%|▎         | 120/3840 [00:34<40:33,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'NonInvasiveFetalECGThorax1', 'run': 0, 'model': 'raw-scale-ridge'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   3%|▎         | 121/3840 [00:37<1:09:08,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'NonInvasiveFetalECGThorax1', 'run': 0, 'model': 'quant'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   3%|▎         | 122/3840 [00:55<6:16:57,  6.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'NonInvasiveFetalECGThorax1', 'run': 0, 'model': 'minirocket'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   3%|▎         | 123/3840 [00:57<4:59:48,  4.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'NonInvasiveFetalECGThorax1', 'run': 0, 'model': 'catch22'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   3%|▎         | 124/3840 [01:02<5:04:08,  4.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'NonInvasiveFetalECGThorax1', 'run': 0, 'model': 'hydra'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   3%|▎         | 125/3840 [01:23<9:53:17,  9.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'NonInvasiveFetalECGThorax1', 'run': 0, 'model': 'tabpfn'}\n",
      "Error processing NonInvasiveFetalECGThorax1, run 0, model tabpfn: Number of classes 42 exceeds the maximal number of classes supported by TabPFN. Consider using a strategy to reduce the number of classes. For code see https://github.com/PriorLabs/tabpfn-extensions/blob/main/src/tabpfn_extensions/many_class/many_class_classifier.py\n",
      "Processing {'dataset': 'NonInvasiveFetalECGThorax1', 'run': 1, 'model': 'raw-scale-ridge'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   3%|▎         | 127/3840 [01:23<5:26:30,  5.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'NonInvasiveFetalECGThorax1', 'run': 1, 'model': 'quant'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   3%|▎         | 128/3840 [01:41<8:43:11,  8.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'NonInvasiveFetalECGThorax1', 'run': 1, 'model': 'minirocket'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   3%|▎         | 129/3840 [01:43<6:56:59,  6.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'NonInvasiveFetalECGThorax1', 'run': 1, 'model': 'catch22'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   3%|▎         | 130/3840 [01:48<6:28:00,  6.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'NonInvasiveFetalECGThorax1', 'run': 1, 'model': 'hydra'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   3%|▎         | 131/3840 [02:10<10:51:57, 10.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'NonInvasiveFetalECGThorax1', 'run': 1, 'model': 'tabpfn'}\n",
      "Error processing NonInvasiveFetalECGThorax1, run 1, model tabpfn: Number of classes 42 exceeds the maximal number of classes supported by TabPFN. Consider using a strategy to reduce the number of classes. For code see https://github.com/PriorLabs/tabpfn-extensions/blob/main/src/tabpfn_extensions/many_class/many_class_classifier.py\n",
      "Processing {'dataset': 'NonInvasiveFetalECGThorax1', 'run': 2, 'model': 'raw-scale-ridge'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   3%|▎         | 133/3840 [02:10<6:07:48,  5.95s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'NonInvasiveFetalECGThorax1', 'run': 2, 'model': 'quant'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   3%|▎         | 134/3840 [02:28<9:08:31,  8.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'NonInvasiveFetalECGThorax1', 'run': 2, 'model': 'minirocket'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   4%|▎         | 135/3840 [02:35<8:42:27,  8.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'NonInvasiveFetalECGThorax1', 'run': 2, 'model': 'catch22'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   4%|▎         | 136/3840 [02:41<7:47:21,  7.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'NonInvasiveFetalECGThorax1', 'run': 2, 'model': 'hydra'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   4%|▎         | 137/3840 [03:02<11:47:43, 11.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'NonInvasiveFetalECGThorax1', 'run': 2, 'model': 'tabpfn'}\n",
      "Error processing NonInvasiveFetalECGThorax1, run 2, model tabpfn: Number of classes 42 exceeds the maximal number of classes supported by TabPFN. Consider using a strategy to reduce the number of classes. For code see https://github.com/PriorLabs/tabpfn-extensions/blob/main/src/tabpfn_extensions/many_class/many_class_classifier.py\n",
      "Processing {'dataset': 'NonInvasiveFetalECGThorax1', 'run': 3, 'model': 'raw-scale-ridge'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   4%|▎         | 139/3840 [03:03<6:45:06,  6.57s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'NonInvasiveFetalECGThorax1', 'run': 3, 'model': 'quant'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   4%|▎         | 140/3840 [03:21<9:35:09,  9.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'NonInvasiveFetalECGThorax1', 'run': 3, 'model': 'minirocket'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   4%|▎         | 141/3840 [03:23<7:41:02,  7.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'NonInvasiveFetalECGThorax1', 'run': 3, 'model': 'catch22'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   4%|▎         | 142/3840 [03:28<7:02:53,  6.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'NonInvasiveFetalECGThorax1', 'run': 3, 'model': 'hydra'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   4%|▎         | 143/3840 [03:54<12:26:45, 12.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'NonInvasiveFetalECGThorax1', 'run': 3, 'model': 'tabpfn'}\n",
      "Error processing NonInvasiveFetalECGThorax1, run 3, model tabpfn: Number of classes 42 exceeds the maximal number of classes supported by TabPFN. Consider using a strategy to reduce the number of classes. For code see https://github.com/PriorLabs/tabpfn-extensions/blob/main/src/tabpfn_extensions/many_class/many_class_classifier.py\n",
      "Processing {'dataset': 'NonInvasiveFetalECGThorax1', 'run': 4, 'model': 'raw-scale-ridge'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   4%|▍         | 145/3840 [03:55<7:05:04,  6.90s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'NonInvasiveFetalECGThorax1', 'run': 4, 'model': 'quant'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   4%|▍         | 146/3840 [04:15<10:13:25,  9.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'NonInvasiveFetalECGThorax1', 'run': 4, 'model': 'minirocket'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   4%|▍         | 147/3840 [04:17<8:11:04,  7.98s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'NonInvasiveFetalECGThorax1', 'run': 4, 'model': 'catch22'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   4%|▍         | 148/3840 [04:22<7:25:48,  7.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'NonInvasiveFetalECGThorax1', 'run': 4, 'model': 'hydra'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   4%|▍         | 149/3840 [04:44<11:45:48, 11.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'NonInvasiveFetalECGThorax1', 'run': 4, 'model': 'tabpfn'}\n",
      "Error processing NonInvasiveFetalECGThorax1, run 4, model tabpfn: Number of classes 42 exceeds the maximal number of classes supported by TabPFN. Consider using a strategy to reduce the number of classes. For code see https://github.com/PriorLabs/tabpfn-extensions/blob/main/src/tabpfn_extensions/many_class/many_class_classifier.py\n",
      "Processing {'dataset': 'TwoPatterns', 'run': 0, 'model': 'raw-scale-ridge'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   4%|▍         | 151/3840 [04:46<6:49:19,  6.66s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'TwoPatterns', 'run': 0, 'model': 'quant'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   4%|▍         | 152/3840 [04:47<5:30:25,  5.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'TwoPatterns', 'run': 0, 'model': 'minirocket'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   4%|▍         | 153/3840 [04:48<4:21:00,  4.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'TwoPatterns', 'run': 0, 'model': 'catch22'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   4%|▍         | 154/3840 [04:50<3:41:24,  3.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'TwoPatterns', 'run': 0, 'model': 'hydra'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   4%|▍         | 155/3840 [04:54<3:49:10,  3.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'TwoPatterns', 'run': 0, 'model': 'tabpfn'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   4%|▍         | 156/3840 [05:02<5:07:56,  5.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'TwoPatterns', 'run': 1, 'model': 'raw-scale-ridge'}\n",
      "Processing {'dataset': 'TwoPatterns', 'run': 1, 'model': 'quant'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   4%|▍         | 158/3840 [05:03<3:09:24,  3.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'TwoPatterns', 'run': 1, 'model': 'minirocket'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   4%|▍         | 159/3840 [05:04<2:36:21,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'TwoPatterns', 'run': 1, 'model': 'catch22'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   4%|▍         | 160/3840 [05:06<2:25:04,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'TwoPatterns', 'run': 1, 'model': 'hydra'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   4%|▍         | 161/3840 [05:10<2:49:26,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'TwoPatterns', 'run': 1, 'model': 'tabpfn'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   4%|▍         | 162/3840 [05:18<4:15:18,  4.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'TwoPatterns', 'run': 2, 'model': 'raw-scale-ridge'}\n",
      "Processing {'dataset': 'TwoPatterns', 'run': 2, 'model': 'quant'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   4%|▍         | 164/3840 [05:19<2:41:24,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'TwoPatterns', 'run': 2, 'model': 'minirocket'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   4%|▍         | 165/3840 [05:20<2:16:16,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'TwoPatterns', 'run': 2, 'model': 'catch22'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   4%|▍         | 166/3840 [05:22<2:10:48,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'TwoPatterns', 'run': 2, 'model': 'hydra'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   4%|▍         | 167/3840 [05:26<2:39:58,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'TwoPatterns', 'run': 2, 'model': 'tabpfn'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   4%|▍         | 168/3840 [05:34<4:07:57,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'TwoPatterns', 'run': 3, 'model': 'raw-scale-ridge'}\n",
      "Processing {'dataset': 'TwoPatterns', 'run': 3, 'model': 'quant'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   4%|▍         | 170/3840 [05:35<2:37:28,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'TwoPatterns', 'run': 3, 'model': 'minirocket'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   4%|▍         | 171/3840 [05:37<2:27:57,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'TwoPatterns', 'run': 3, 'model': 'catch22'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   4%|▍         | 172/3840 [05:39<2:19:26,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'TwoPatterns', 'run': 3, 'model': 'hydra'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   5%|▍         | 173/3840 [05:43<2:45:55,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'TwoPatterns', 'run': 3, 'model': 'tabpfn'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   5%|▍         | 174/3840 [05:51<4:11:56,  4.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'TwoPatterns', 'run': 4, 'model': 'raw-scale-ridge'}\n",
      "Processing {'dataset': 'TwoPatterns', 'run': 4, 'model': 'quant'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   5%|▍         | 176/3840 [05:52<2:40:02,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'TwoPatterns', 'run': 4, 'model': 'minirocket'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   5%|▍         | 177/3840 [05:53<2:14:30,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'TwoPatterns', 'run': 4, 'model': 'catch22'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   5%|▍         | 178/3840 [05:55<2:09:34,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'TwoPatterns', 'run': 4, 'model': 'hydra'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   5%|▍         | 179/3840 [05:59<2:38:46,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'TwoPatterns', 'run': 4, 'model': 'tabpfn'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   5%|▌         | 192/3840 [06:07<43:32,  1.40it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'GestureMidAirD3', 'run': 0, 'model': 'tabpfn'}\n",
      "Error processing GestureMidAirD3, run 0, model tabpfn: Number of classes 26 exceeds the maximal number of classes supported by TabPFN. Consider using a strategy to reduce the number of classes. For code see https://github.com/PriorLabs/tabpfn-extensions/blob/main/src/tabpfn_extensions/many_class/many_class_classifier.py\n",
      "Processing {'dataset': 'GestureMidAirD3', 'run': 1, 'model': 'tabpfn'}\n",
      "Error processing GestureMidAirD3, run 1, model tabpfn: Number of classes 26 exceeds the maximal number of classes supported by TabPFN. Consider using a strategy to reduce the number of classes. For code see https://github.com/PriorLabs/tabpfn-extensions/blob/main/src/tabpfn_extensions/many_class/many_class_classifier.py\n",
      "Processing {'dataset': 'GestureMidAirD3', 'run': 2, 'model': 'tabpfn'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   5%|▌         | 204/3840 [06:07<20:15,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing GestureMidAirD3, run 2, model tabpfn: Number of classes 26 exceeds the maximal number of classes supported by TabPFN. Consider using a strategy to reduce the number of classes. For code see https://github.com/PriorLabs/tabpfn-extensions/blob/main/src/tabpfn_extensions/many_class/many_class_classifier.py\n",
      "Processing {'dataset': 'GestureMidAirD3', 'run': 3, 'model': 'tabpfn'}\n",
      "Error processing GestureMidAirD3, run 3, model tabpfn: Number of classes 26 exceeds the maximal number of classes supported by TabPFN. Consider using a strategy to reduce the number of classes. For code see https://github.com/PriorLabs/tabpfn-extensions/blob/main/src/tabpfn_extensions/many_class/many_class_classifier.py\n",
      "Processing {'dataset': 'GestureMidAirD3', 'run': 4, 'model': 'tabpfn'}\n",
      "Error processing GestureMidAirD3, run 4, model tabpfn: Number of classes 26 exceeds the maximal number of classes supported by TabPFN. Consider using a strategy to reduce the number of classes. For code see https://github.com/PriorLabs/tabpfn-extensions/blob/main/src/tabpfn_extensions/many_class/many_class_classifier.py\n",
      "Processing {'dataset': 'ToeSegmentation1', 'run': 0, 'model': 'tabpfn'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   6%|▌         | 216/3840 [06:08<14:45,  4.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing {'dataset': 'ToeSegmentation1', 'run': 1, 'model': 'tabpfn'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   6%|▌         | 221/3840 [06:09<1:40:47,  1.67s/it]\n",
      "[W1112 10:25:11.163438672 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())\n",
      "[W1112 10:25:11.163550766 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())\n",
      "[W1112 10:25:11.163792777 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())\n",
      "[W1112 10:25:11.165996461 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     31\u001b[39m model.fit(X_train, y_train)\n\u001b[32m     32\u001b[39m training_time = perf_counter() - start_time\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m y_pred = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m test_accuracy = accuracy_score(y_test, y_pred)\n\u001b[32m     36\u001b[39m stats[\u001b[33m\"\u001b[39m\u001b[33mtest_accuracy\u001b[39m\u001b[33m\"\u001b[39m] = test_accuracy\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/repos/AutoTSC/.venv/lib/python3.12/site-packages/aeon/classification/base.py:159\u001b[39m, in \u001b[36mBaseClassifier.predict\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;66;03m# Check if X is equal length but that is different to the length seen in fit\u001b[39;00m\n\u001b[32m    158\u001b[39m \u001b[38;5;28mself\u001b[39m._check_shape(X)\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/repos/AutoTSC/.venv/lib/python3.12/site-packages/aeon/classification/sklearn/_wrapper.py:44\u001b[39m, in \u001b[36mSklearnClassifierWrapper._predict\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclassifier_\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/repos/AutoTSC/.venv/lib/python3.12/site-packages/tabpfn_common_utils/telemetry/core/decorators.py:288\u001b[39m, in \u001b[36mtrack_model_call.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    286\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args: Any, **kwargs: Any) -> Any:\n\u001b[32m--> \u001b[39m\u001b[32m288\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_safe_call_with_telemetry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_names\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/repos/AutoTSC/.venv/lib/python3.12/site-packages/tabpfn_common_utils/telemetry/core/decorators.py:332\u001b[39m, in \u001b[36m_safe_call_with_telemetry\u001b[39m\u001b[34m(func, args, kwargs, model_method, param_names)\u001b[39m\n\u001b[32m    330\u001b[39m \u001b[38;5;66;03m# Step 2: Run the actual function\u001b[39;00m\n\u001b[32m    331\u001b[39m start = time.perf_counter()\n\u001b[32m--> \u001b[39m\u001b[32m332\u001b[39m result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    333\u001b[39m duration_ms = \u001b[38;5;28mint\u001b[39m((time.perf_counter() - start) * \u001b[32m1000\u001b[39m)\n\u001b[32m    335\u001b[39m \u001b[38;5;66;03m# Step 3: Send telemetry event\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/repos/AutoTSC/.venv/lib/python3.12/site-packages/tabpfn/classifier.py:1029\u001b[39m, in \u001b[36mTabPFNClassifier.predict\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m   1019\u001b[39m \u001b[38;5;129m@track_model_call\u001b[39m(model_method=\u001b[33m\"\u001b[39m\u001b[33mpredict\u001b[39m\u001b[33m\"\u001b[39m, param_names=[\u001b[33m\"\u001b[39m\u001b[33mX\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1020\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: XType) -> np.ndarray:\n\u001b[32m   1021\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Predict the class labels for the provided input samples.\u001b[39;00m\n\u001b[32m   1022\u001b[39m \n\u001b[32m   1023\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1027\u001b[39m \u001b[33;03m        The predicted class labels as a NumPy array.\u001b[39;00m\n\u001b[32m   1028\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1029\u001b[39m     probas = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1030\u001b[39m     y_pred = np.argmax(probas, axis=\u001b[32m1\u001b[39m)\n\u001b[32m   1031\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mlabel_encoder_\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.label_encoder_ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.0-linux-x86_64-gnu/lib/python3.12/contextlib.py:81\u001b[39m, in \u001b[36mContextDecorator.__call__.<locals>.inner\u001b[39m\u001b[34m(*args, **kwds)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minner\u001b[39m(*args, **kwds):\n\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._recreate_cm():\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/repos/AutoTSC/.venv/lib/python3.12/site-packages/tabpfn/classifier.py:1104\u001b[39m, in \u001b[36mTabPFNClassifier._predict_proba\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m   1092\u001b[39m \u001b[38;5;129m@config_context\u001b[39m(transform_output=\u001b[33m\"\u001b[39m\u001b[33mdefault\u001b[39m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m   1093\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_predict_proba\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: XType) -> np.ndarray:\n\u001b[32m   1094\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Predict the probabilities of the classes for the provided input samples.\u001b[39;00m\n\u001b[32m   1095\u001b[39m \n\u001b[32m   1096\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1101\u001b[39m \u001b[33;03m        Shape (n_samples, n_classes).\u001b[39;00m\n\u001b[32m   1102\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   1103\u001b[39m     probas = (\n\u001b[32m-> \u001b[39m\u001b[32m1104\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raw_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_logits\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m.float().detach().cpu().numpy()\n\u001b[32m   1105\u001b[39m     )\n\u001b[32m   1106\u001b[39m     probas = \u001b[38;5;28mself\u001b[39m._maybe_reweight_probas(probas=probas)\n\u001b[32m   1107\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.inference_config_.USE_SKLEARN_16_DECIMAL_PRECISION:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/repos/AutoTSC/.venv/lib/python3.12/site-packages/tabpfn/classifier.py:1012\u001b[39m, in \u001b[36mTabPFNClassifier._raw_predict\u001b[39m\u001b[34m(self, X, return_logits, return_raw_logits)\u001b[39m\n\u001b[32m   1009\u001b[39m     X = fix_dtypes(X, cat_indices=\u001b[38;5;28mself\u001b[39m.inferred_categorical_indices_)\n\u001b[32m   1010\u001b[39m     X = process_text_na_dataframe(X, ord_encoder=\u001b[38;5;28mself\u001b[39m.preprocessor_)\n\u001b[32m-> \u001b[39m\u001b[32m1012\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_inference_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_logits\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_logits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_raw_logits\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_raw_logits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1017\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/repos/AutoTSC/.venv/lib/python3.12/site-packages/tabpfn/classifier.py:1331\u001b[39m, in \u001b[36mTabPFNClassifier.forward\u001b[39m\u001b[34m(self, X, use_inference_mode, return_logits, return_raw_logits)\u001b[39m\n\u001b[32m   1328\u001b[39m     \u001b[38;5;28mself\u001b[39m.executor_.use_torch_inference_mode(use_inference=use_inference_mode)\n\u001b[32m   1330\u001b[39m outputs = []\n\u001b[32m-> \u001b[39m\u001b[32m1331\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexecutor_\u001b[49m\u001b[43m.\u001b[49m\u001b[43miter_outputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1332\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1333\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevices\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevices_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1334\u001b[39m \u001b[43m    \u001b[49m\u001b[43mautocast\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43muse_autocast_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1335\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1336\u001b[39m \u001b[43m    \u001b[49m\u001b[43moriginal_ndim\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m.\u001b[49m\u001b[43mndim\u001b[49m\n\u001b[32m   1338\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# This block correctly handles both single configs and lists of configs\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/repos/AutoTSC/.venv/lib/python3.12/site-packages/tabpfn/inference.py:547\u001b[39m, in \u001b[36mInferenceEngineCachePreprocessing.iter_outputs\u001b[39m\u001b[34m(self, X, devices, autocast, only_return_standard_out)\u001b[39m\n\u001b[32m    531\u001b[39m model_forward_functions = (\n\u001b[32m    532\u001b[39m     partial(\n\u001b[32m    533\u001b[39m         \u001b[38;5;28mself\u001b[39m._call_model,\n\u001b[32m   (...)\u001b[39m\u001b[32m    543\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m sorted_indices\n\u001b[32m    544\u001b[39m )\n\u001b[32m    545\u001b[39m outputs = parallel_execute(devices, model_forward_functions)\n\u001b[32m--> \u001b[39m\u001b[32m547\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msorted_indices\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    548\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_move_and_squeeze_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevices\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mensemble_configs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.inference_mode:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/repos/AutoTSC/.venv/lib/python3.12/site-packages/tabpfn/parallel_execute.py:61\u001b[39m, in \u001b[36mparallel_execute\u001b[39m\u001b[34m(devices, functions)\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Evaluate the given functions in parallel across `devices`.\u001b[39;00m\n\u001b[32m     43\u001b[39m \n\u001b[32m     44\u001b[39m \u001b[33;03mThe function evaluations are parallelised using Python threads, so this will only\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     57\u001b[39m \u001b[33;03m    as `functions`.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(devices) == \u001b[32m1\u001b[39m:\n\u001b[32m     60\u001b[39m     \u001b[38;5;66;03m# If we only have one device then just use the current thread to avoid overhead.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m _execute_in_current_thread(devices[\u001b[32m0\u001b[39m], functions)\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m _execute_with_multithreading(devices, functions)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/repos/AutoTSC/.venv/lib/python3.12/site-packages/tabpfn/parallel_execute.py:70\u001b[39m, in \u001b[36m_execute_in_current_thread\u001b[39m\u001b[34m(device, functions)\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_execute_in_current_thread\u001b[39m(\n\u001b[32m     67\u001b[39m     device: torch.device, functions: Iterable[ParallelFunction[R_co]]\n\u001b[32m     68\u001b[39m ) -> Generator[R_co]:\n\u001b[32m     69\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m function \u001b[38;5;129;01min\u001b[39;00m functions:\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_parallel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/repos/AutoTSC/.venv/lib/python3.12/site-packages/tabpfn/inference.py:592\u001b[39m, in \u001b[36mInferenceEngineCachePreprocessing._call_model\u001b[39m\u001b[34m(self, device, is_parallel, X_train, X_test, y_train, cat_ix, autocast, only_return_standard_out, model_index, save_peak_mem)\u001b[39m\n\u001b[32m    586\u001b[39m batched_cat_ix = [cat_ix]\n\u001b[32m    588\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m (\n\u001b[32m    589\u001b[39m     get_autocast_context(device, enabled=autocast),\n\u001b[32m    590\u001b[39m     torch.inference_mode(\u001b[38;5;28mself\u001b[39m.inference_mode),\n\u001b[32m    591\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m592\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    593\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX_full\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    594\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    595\u001b[39m \u001b[43m        \u001b[49m\u001b[43monly_return_standard_out\u001b[49m\u001b[43m=\u001b[49m\u001b[43monly_return_standard_out\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    596\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcategorical_inds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatched_cat_ix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    597\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/repos/AutoTSC/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/repos/AutoTSC/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/repos/AutoTSC/.venv/lib/python3.12/site-packages/tabpfn/architectures/base/transformer.py:563\u001b[39m, in \u001b[36mPerFeatureTransformer.forward\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    557\u001b[39m     embedded_input, single_eval_pos = \u001b[38;5;28mself\u001b[39m.add_thinking_tokens(\n\u001b[32m    558\u001b[39m         embedded_input,\n\u001b[32m    559\u001b[39m         single_eval_pos,\n\u001b[32m    560\u001b[39m     )\n\u001b[32m    562\u001b[39m recompute_layer = \u001b[38;5;28mself\u001b[39m.recompute_layer \u001b[38;5;129;01mor\u001b[39;00m force_recompute_layer\n\u001b[32m--> \u001b[39m\u001b[32m563\u001b[39m encoder_out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransformer_encoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    564\u001b[39m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    565\u001b[39m \u001b[43m        \u001b[49m\u001b[43membedded_input\u001b[49m\n\u001b[32m    566\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransformer_decoder\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43membedded_input\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43msingle_eval_pos\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    568\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    569\u001b[39m \u001b[43m    \u001b[49m\u001b[43msingle_eval_pos\u001b[49m\u001b[43m=\u001b[49m\u001b[43msingle_eval_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    570\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_trainset_representation\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcache_trainset_representation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    571\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrecompute_layer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrecompute_layer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    572\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# b s f+1 e -> b s f+1 e\u001b[39;00m\n\u001b[32m    574\u001b[39m \u001b[38;5;66;03m# If we are using a decoder\u001b[39;00m\n\u001b[32m    575\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transformer_decoder:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/repos/AutoTSC/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/repos/AutoTSC/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/repos/AutoTSC/.venv/lib/python3.12/site-packages/tabpfn/architectures/base/transformer.py:87\u001b[39m, in \u001b[36mLayerStack.forward\u001b[39m\u001b[34m(self, x, recompute_layer, **kwargs)\u001b[39m\n\u001b[32m     85\u001b[39m         x = checkpoint(partial(layer, **kwargs), x, use_reentrant=\u001b[38;5;28;01mFalse\u001b[39;00m)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m     86\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m         x = \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/repos/AutoTSC/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/repos/AutoTSC/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/repos/AutoTSC/.venv/lib/python3.12/site-packages/tabpfn/architectures/base/layer.py:421\u001b[39m, in \u001b[36mPerFeatureEncoderLayer.forward\u001b[39m\u001b[34m(self, state, single_eval_pos, cache_trainset_representation, att_src)\u001b[39m\n\u001b[32m    411\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[32m    412\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPre-norm implementation is wrong, as the residual should never\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    413\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m be layer normed here.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    414\u001b[39m     )\n\u001b[32m    415\u001b[39m     state = layer_norm(\n\u001b[32m    416\u001b[39m         state,\n\u001b[32m    417\u001b[39m         allow_inplace=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    418\u001b[39m         save_peak_mem_factor=save_peak_mem_factor,\n\u001b[32m    419\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m421\u001b[39m state = \u001b[43msublayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    422\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pre_norm:\n\u001b[32m    423\u001b[39m     state = layer_norm(\n\u001b[32m    424\u001b[39m         state,\n\u001b[32m    425\u001b[39m         allow_inplace=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    426\u001b[39m         save_peak_mem_factor=save_peak_mem_factor,\n\u001b[32m    427\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/repos/AutoTSC/.venv/lib/python3.12/site-packages/tabpfn/architectures/base/layer.py:307\u001b[39m, in \u001b[36mPerFeatureEncoderLayer.forward.<locals>.attn_between_features\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m    305\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mattn_between_features\u001b[39m(x: torch.Tensor) -> torch.Tensor:\n\u001b[32m    306\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.self_attn_between_features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m307\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mself_attn_between_features\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    308\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    309\u001b[39m \u001b[43m        \u001b[49m\u001b[43msave_peak_mem_factor\u001b[49m\u001b[43m=\u001b[49m\u001b[43msave_peak_mem_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[43m        \u001b[49m\u001b[43madd_input\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_inplace\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/repos/AutoTSC/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/repos/AutoTSC/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/repos/AutoTSC/.venv/lib/python3.12/site-packages/tabpfn/architectures/base/attention/full_attention.py:354\u001b[39m, in \u001b[36mMultiHeadAttention.forward\u001b[39m\u001b[34m(self, x, x_kv, cache_kv, add_input, allow_inplace, save_peak_mem_factor, reuse_first_head_kv, only_cache_first_head_kv, use_cached_kv)\u001b[39m\n\u001b[32m    337\u001b[39m         \u001b[38;5;28mself\u001b[39m._k_cache = torch.empty(\n\u001b[32m    338\u001b[39m             batch_size,\n\u001b[32m    339\u001b[39m             seqlen_kv,\n\u001b[32m   (...)\u001b[39m\u001b[32m    343\u001b[39m             dtype=x.dtype,\n\u001b[32m    344\u001b[39m         )\n\u001b[32m    345\u001b[39m         \u001b[38;5;28mself\u001b[39m._v_cache = torch.empty(\n\u001b[32m    346\u001b[39m             batch_size,\n\u001b[32m    347\u001b[39m             seqlen_kv,\n\u001b[32m   (...)\u001b[39m\u001b[32m    351\u001b[39m             dtype=x.dtype,\n\u001b[32m    352\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m output: torch.Tensor = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_compute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mx_kv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_k_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_v_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_kv_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_kv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_kv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cached_kv\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cached_kv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m    \u001b[49m\u001b[43madd_input\u001b[49m\u001b[43m=\u001b[49m\u001b[43madd_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    363\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_inplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_inplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    364\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_peak_mem_factor\u001b[49m\u001b[43m=\u001b[49m\u001b[43msave_peak_mem_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    365\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreuse_first_head_kv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreuse_first_head_kv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    366\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    367\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output.reshape(x_shape_after_transpose[:-\u001b[32m1\u001b[39m] + output.shape[-\u001b[32m1\u001b[39m:])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/repos/AutoTSC/.venv/lib/python3.12/site-packages/tabpfn/architectures/base/memory.py:100\u001b[39m, in \u001b[36msupport_save_peak_mem_factor.<locals>.method_\u001b[39m\u001b[34m(self, x, add_input, allow_inplace, save_peak_mem_factor, *args, **kwargs)\u001b[39m\n\u001b[32m     97\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m add_input:\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x + \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m method(\u001b[38;5;28mself\u001b[39m, x, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/repos/AutoTSC/.venv/lib/python3.12/site-packages/tabpfn/architectures/base/attention/full_attention.py:504\u001b[39m, in \u001b[36mMultiHeadAttention._compute\u001b[39m\u001b[34m(self, x, x_kv, k_cache, v_cache, kv_cache, cache_kv, use_cached_kv, reuse_first_head_kv)\u001b[39m\n\u001b[32m    491\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Attention computation.\u001b[39;00m\n\u001b[32m    492\u001b[39m \u001b[33;03mCalled by 'forward', potentially on shards, once shapes have been normalized.\u001b[39;00m\n\u001b[32m    493\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    494\u001b[39m q, k, v, kv, qkv = \u001b[38;5;28mself\u001b[39m.compute_qkv(\n\u001b[32m    495\u001b[39m     x,\n\u001b[32m    496\u001b[39m     x_kv,\n\u001b[32m   (...)\u001b[39m\u001b[32m    502\u001b[39m     reuse_first_head_kv=reuse_first_head_kv,\n\u001b[32m    503\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m504\u001b[39m attention_head_outputs = \u001b[43mMultiHeadAttention\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompute_attention_heads\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    505\u001b[39m \u001b[43m    \u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    506\u001b[39m \u001b[43m    \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    507\u001b[39m \u001b[43m    \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    508\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    509\u001b[39m \u001b[43m    \u001b[49m\u001b[43mqkv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    510\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    511\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msoftmax_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    512\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    513\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m torch.einsum(\n\u001b[32m    514\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m... h d, h d s -> ... s\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    515\u001b[39m     attention_head_outputs,\n\u001b[32m    516\u001b[39m     \u001b[38;5;28mself\u001b[39m._w_out,\n\u001b[32m    517\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/repos/AutoTSC/.venv/lib/python3.12/site-packages/tabpfn/architectures/base/attention/full_attention.py:647\u001b[39m, in \u001b[36mMultiHeadAttention.compute_attention_heads\u001b[39m\u001b[34m(q, k, v, kv, qkv, dropout_p, softmax_scale)\u001b[39m\n\u001b[32m    637\u001b[39m         k = MultiHeadAttention.broadcast_kv_across_heads(\n\u001b[32m    638\u001b[39m             k,\n\u001b[32m    639\u001b[39m             share_kv_across_n_heads,\n\u001b[32m    640\u001b[39m         )\n\u001b[32m    641\u001b[39m         v = MultiHeadAttention.broadcast_kv_across_heads(\n\u001b[32m    642\u001b[39m             v,\n\u001b[32m    643\u001b[39m             share_kv_across_n_heads,\n\u001b[32m    644\u001b[39m         )\n\u001b[32m    646\u001b[39m     attention_head_outputs = (\n\u001b[32m--> \u001b[39m\u001b[32m647\u001b[39m         \u001b[43mMultiHeadAttention\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscaled_dot_product_attention_chunked\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m            \u001b[49m\u001b[43mq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m            \u001b[49m\u001b[43mk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m            \u001b[49m\u001b[43mv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mextra_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    654\u001b[39m     )\n\u001b[32m    655\u001b[39m     attention_head_outputs = attention_head_outputs.transpose(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m)\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/repos/AutoTSC/.venv/lib/python3.12/site-packages/tabpfn/architectures/base/attention/full_attention.py:595\u001b[39m, in \u001b[36mMultiHeadAttention.scaled_dot_product_attention_chunked\u001b[39m\u001b[34m(q, k, v, dropout_p, max_batch_size, **extra_inputs)\u001b[39m\n\u001b[32m    592\u001b[39m     output_chunks.append(chunk_output)\n\u001b[32m    594\u001b[39m \u001b[38;5;66;03m# Concatenate results along batch dimension\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m595\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_chunks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "all_combinations = list(product(datasets, range(n_runs), model_types))\n",
    "\n",
    "last_dataset = None\n",
    "X_train, y_train, X_test, y_test = None, None, None, None\n",
    "\n",
    "for ds, run, model_name in tqdm(all_combinations, desc=\"Processing\"):\n",
    "    try: \n",
    "        model = get_model(model_name)\n",
    "        stats = {\n",
    "            \"dataset\": ds,\n",
    "            \"run\": run,\n",
    "            \"model\": model_name,\n",
    "        }\n",
    "\n",
    "        hash_val = pl.DataFrame([stats]).hash_rows(\n",
    "            seed=42, seed_1=1, seed_2=2, seed_3=3\n",
    "        ).item()\n",
    "        file = f\"{write_dir}/{hash_val}.parquet\"\n",
    "\n",
    "        if os.path.exists(file):\n",
    "            #print(f'Skipping {stats}')\n",
    "            continue\n",
    "        else:\n",
    "            print(f'Processing {stats}')\n",
    "\n",
    "        if ds != last_dataset:\n",
    "            X_train, y_train, X_test, y_test = utils.load_dataset(ds)\n",
    "            last_dataset = ds\n",
    "\n",
    "        start_time = perf_counter()\n",
    "        model.fit(X_train, y_train)\n",
    "        training_time = perf_counter() - start_time\n",
    "        y_pred = model.predict(X_test)\n",
    "        test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        stats[\"test_accuracy\"] = test_accuracy\n",
    "        stats[\"training_time\"] = training_time\n",
    "\n",
    "        df_stat = pl.DataFrame([stats])\n",
    "        df_stat.write_parquet(file)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {ds}, run {run}, model {model_name}: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4a24ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_parquet(f'{write_dir}/*.parquet').filter(pl.col(\"dataset\").is_in(datasets))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f286f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74f14a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = df.group_by('dataset', 'model').agg([\n",
    "    pl.col('test_accuracy').mean()\n",
    "]).sort('test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4c4df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "together_dataset = set(\n",
    "    gdf.filter(pl.col('model') == 'tabpfn')['dataset']\n",
    ").intersection(\n",
    "    set(gdf.filter(pl.col('model') == 'quant')['dataset'])\n",
    ")\n",
    "v1 = gdf.filter(pl.col('model') == 'tabpfn').filter(pl.col('dataset').is_in(together_dataset)).sort('dataset')['test_accuracy']\n",
    "v2 = gdf.filter(pl.col('model') == 'quant').filter(pl.col('dataset').is_in(together_dataset)).sort('dataset')['test_accuracy']\n",
    "plt.scatter(v1, v2)\n",
    "# plot read line y=x\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--')\n",
    "plt.xlabel('TabPFN Test Accuracy')\n",
    "plt.ylabel('QUANT Test Accuracy')\n",
    "plt.title('Model Performance Comparison: TabPFN vs QUANT')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8816476",
   "metadata": {},
   "outputs": [],
   "source": [
    "together_dataset = set(\n",
    "    gdf.filter(pl.col('model') == 'tabpfn')['dataset']\n",
    ").intersection(\n",
    "    set(gdf.filter(pl.col('model') == 'raw-scale-ridge')['dataset'])\n",
    ")\n",
    "v1 = gdf.filter(pl.col('model') == 'tabpfn').filter(pl.col('dataset').is_in(together_dataset)).sort('dataset')['test_accuracy']\n",
    "v2 = gdf.filter(pl.col('model') == 'raw-scale-ridge').filter(pl.col('dataset').is_in(together_dataset)).sort('dataset')['test_accuracy']\n",
    "plt.scatter(v1, v2)\n",
    "# plot read line y=x\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--')\n",
    "plt.xlabel('TabPFN Test Accuracy')\n",
    "plt.ylabel('Raw-scale Ridge Classifier Accuracy')\n",
    "plt.title('Model Performance Comparison: TabPFN vs Raw-scale Ridge Classifier')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a901b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = gdf.filter(pl.col('model') == 'raw-scale-ridge').sort('dataset')['test_accuracy']\n",
    "v2 = gdf.filter(pl.col('model') == 'quant').sort('dataset')['test_accuracy']\n",
    "plt.scatter(v1, v2)\n",
    "# plot read line y=x\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--')\n",
    "plt.xlabel('Raw-scale Ridge Classifier Accuracy')\n",
    "plt.ylabel('QUANT Classifier Accuracy')\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f400d556",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = gdf.filter(pl.col('model') == 'quant').sort('dataset')['test_accuracy']\n",
    "v2 = gdf.filter(pl.col('model') == 'minirocket').sort('dataset')['test_accuracy']\n",
    "plt.scatter(v1, v2)\n",
    "# plot read line y=x\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--')\n",
    "plt.xlabel('QUANT Classifier Accuracy')\n",
    "plt.ylabel('MiniRocket Classifier Accuracy')\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912d36fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = gdf.filter(pl.col('model') == 'catch22').sort('dataset')['test_accuracy']\n",
    "v2 = gdf.filter(pl.col('model') == 'minirocket').sort('dataset')['test_accuracy']\n",
    "plt.scatter(v1, v2)\n",
    "# plot read line y=x\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--')\n",
    "plt.xlabel('Catch22 Classifier Accuracy')\n",
    "plt.ylabel('MiniRocket Classifier Accuracy')\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22586e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = gdf.filter(pl.col('model') == 'catch22').sort('dataset')['test_accuracy']\n",
    "v2 = gdf.filter(pl.col('model') == 'raw-scale-ridge').sort('dataset')['test_accuracy']\n",
    "plt.scatter(v1, v2)\n",
    "# plot read line y=x\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--')\n",
    "plt.xlabel('Catch22 Classifier Accuracy')\n",
    "plt.ylabel('Raw-scale Ridge Classifier Accuracy')\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3ba214",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = df.group_by('dataset', 'model').agg([\n",
    "    pl.col('training_time').mean()\n",
    "]).sort('dataset', 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e4ddbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 20))\n",
    "sns.stripplot(data=gdf, y=\"dataset\", x=\"training_time\", hue=\"model\", dodge=False)\n",
    "plt.grid(True)\n",
    "plt.xscale('log')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e873dfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = df.group_by('dataset', 'model').agg([\n",
    "    pl.col('test_accuracy').mean()\n",
    "]).sort('dataset', 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41ce67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dataset'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2543e135",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 20))\n",
    "sns.stripplot(data=gdf, y=\"dataset\", x=\"test_accuracy\", hue=\"model\", dodge=False)\n",
    "plt.grid(True)\n",
    "plt.xscale('log')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d244e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = df.group_by('dataset', 'model').agg([\n",
    "    pl.col('test_accuracy').mean(),\n",
    "    pl.col('training_time').mean()\n",
    "]).sort('dataset', 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9a0bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=gdf, x='training_time', y='test_accuracy', hue='model')\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08d6386",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AutoTSC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
